
The section highlights that a **"good index will stay a good index until the end of time" if nothing changes**, but in reality, changes are inevitable, leading to a decline in performance. It outlines four common causes for this decline:
### Causes for Indexes Losing Effectiveness

1. **Queries Changed**
    
    - **Problem:** When the SQL queries executed against a table evolve, the indexes previously designed for them might no longer be optimal or even usable. This often happens because the **leftmost prefix requirement** (the principle that a query must use one or more columns from the leftmost part of a composite index to utilize it) is no longer met by the new query conditions.
    - **Consequence:** In the worst-case scenario, if MySQL cannot find another suitable index, the query might revert to a **full table scan**, which significantly degrades performance. More commonly, MySQL might fall back to a less efficient existing index, leading to noticeably poor response times.
    - **Solution:** If query changes were necessary, the solution involves **re-indexing for the new query variations**. A **query analysis** combined with the `EXPLAIN` command can quickly reveal if this is the cause.

2. **Excessive, Duplicate, and Unused Indexes**
    
    - **Problem:** While indexes are essential, their overabundance can ironically hinder performance.
        - **Excessive Indexes:** ==Too many indexes lead to **increased index size**, consuming more RAM and reducing the memory available for other indexes. ==Furthermore, every time data is written (inserted, updated, or deleted), ==MySQL must **check, update, and potentially reorganize** every index, leading to a **decrease in write performance**.==
        - **Duplicate Indexes:** A duplicate index exists when another index can fully cover its functionality, often because it's a leftmost prefix of a larger composite index. MySQL issues a warning when you create a duplicate index, but you typically need to explicitly `SHOW WARNINGS` to see it.
        - **Unused Indexes:** These are indexes that MySQL is not utilizing for any queries. They still consume storage and incur the write performance overhead without providing any benefit. Identifying them can be tricky, as an index might be used infrequently (e.g., by a monthly analytics query).
    - **Solution/Tools:**
        - For **duplicate indexes**, the `pt-duplicate-key-checker` tool can safely identify and report them. The tool can even provide the `ALTER TABLE ... DROP INDEX` statement to remove them.
        - For **unused indexes**, you can query `sys.schema_unused_indexes` (excluding `performance_schema`).

```sql
SELECT * FROM sys.schema_unused_indexes
WHERE object_schema NOT IN ('performance_schema');
```

- **Caution when dropping indexes:** It's critical to **be careful when dropping an index**, especially in production. If a dropped index was used by a query and MySQL cannot find another suitable index, the query might revert to a full table scan, potentially causing a ripple effect of performance degradation or even an **application outage**. MySQL 8.0+ introduced ==**invisible indexes**== as a safer way to verify: you can make an index invisible, observe performance, and if no issues arise, then drop it permanently. ==Making an index visible again is nearly instantaneous, whereas re-adding it on large tables can take a long time.==

3. **Extreme Selectivity**
    
    - **Definition:**
        - **Cardinality** is the number of unique values within an index. An index on values a, a, b, b has a cardinality of 2: a and b are the two unique values.
        - **Selectivity** is calculated as **cardinality divided by the number of rows in the table**. It ranges from 0 to 1, with 1 indicating a unique index (a unique value for every row).
	        - Using the same example, a, a, b, b, where each value is one row, the index selectivity is 2 / 4 = 0.5
	- **Example:**
		- A classic example is an index on a column with only two possible values: yes or no, true or false, coffee or tea, on so on. If the table has 100,000 rows, then selectivity is practically zero: 2 / 100,000 = 0.00002. It’s an index, but not a good one because each value could match many rows. How many? Flip the division: 100,000 rows / 2 unique values = 50,000 rows per value. If MySQL were to use this index (which is unlikely), a single index lookup could match 50,000 rows. That presumes values are evenly distributed, but what if 99,999 rows have value coffee and only 1 row has value tea? Then the index works great for tea but terribly for coffee.
    - **Problem:**
        - **Extremely Low Selectivity:** An index with very low selectivity (approaching 0) offers **little leverage** because each unique value might match a large number of rows. For instance, an index on a boolean column (e.g., 'yes' or 'no') in a large table would have extremely low selectivity. ==MySQL might be **unlikely to choose such an index** even if it exists, as it could be faster to perform a full table scan. This is because scanning 50,000 rows (from a hypothetical 100,000-row table with only two unique values) using an index, especially a secondary one that requires primary key lookups for full rows, might be less efficient than a full table scan.==
        - **Extremely High Selectivity:** While generally good, if a nonunique secondary index approaches a selectivity of 1, it might suggest that the index could be unique, or that the query could be rewritten to use the primary key. ==A multitude of highly selective secondary indexes might also indicate that a different data store (e.g., Elasticsearch) would be better suited for the application's search patterns.==
    - **Solution:** Consider creating a **better, more selective index**, rewriting the query to use an existing more selective index, or altering the schema for better data organization.

4. **It’s a Trap! (When MySQL Chooses Another Index)**
    
    - **Problem:** In very rare cases, **MySQL's optimizer chooses a suboptimal index** even when a better index exists that would lead to faster query execution. This is usually your last suspicion if a query is inexplicably slow despite using an index.
    - **Cause:** The most common reason for this misjudgment is **inaccurate index statistics**. Index statistics are MySQL's estimates of how values are distributed within an index, which are gathered by random sampling of index pages. If these statistics diverge significantly from reality (e.g., after a large number of modifications), MySQL might make a poor choice.
    - **When Index Statistics are Updated:**
        - When a table is first opened.
        - When `ANALYZE TABLE` is run on the table.
        - After 1/16th of the table has been modified since the last update.
        - If `innodb_stats_on_metadata` is enabled and `SHOW INDEX` or `SHOW TABLE STATUS` is run, or `INFORMATION_SCHEMA.TABLES` or `INFORMATION_SCHEMA.STATISTICS` is queried.
    - **Solution:** Running `ANALYZE TABLE` is generally **safe and fast**, and it updates index statistics. However, be cautious on a busy server, as it requires a flush lock (except in Percona Server), which can temporarily block all queries accessing the table.
